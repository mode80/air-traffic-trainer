<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Pilot Radio Practice</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');

        :root {
            --primary: #5D5CDE;
            --accent: #3F3FC4;
            --light-bg: #FFFFFF;
            --dark-bg: #181818;
            --light-text: #333333;
            --dark-text: #F0F0F0;
            --light-card: #F5F5F5;
            --dark-card: #262626;
            --light-border: #E0E0E0;
            --dark-border: #404040;
            --recording: #FF4A4A;
        }

        body {
            font-family: 'Inter', sans-serif;
            transition: background-color 0.3s, color 0.3s;
        }

        .airport-diagram {
            width: 100%;
            height: 180px;
            border-radius: 0.5rem;
            background-color: #E0E0E0;
        }

        .dark .airport-diagram {
            background-color: #303030;
        }

        /* Loading animation */
        .loading-dots span {
            animation: loadingDot 1.4s infinite ease-in-out both;
            display: inline-block;
            width: 8px;
            height: 8px;
            border-radius: 50%;
            margin-right: 4px;
        }

        .loading-dots span:nth-child(1) {
            animation-delay: -0.32s;
        }

        .loading-dots span:nth-child(2) {
            animation-delay: -0.16s;
        }

        @keyframes loadingDot {
            0%, 80%, 100% { 
                transform: scale(0);
            }
            40% { 
                transform: scale(1.0);
            }
        }

        /* Pulse animation for recording indicator */
        @keyframes pulse {
            0% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(255, 74, 74, 0.7);
            }
            
            70% {
                transform: scale(1);
                box-shadow: 0 0 0 10px rgba(255, 74, 74, 0);
            }
            
            100% {
                transform: scale(0.95);
                box-shadow: 0 0 0 0 rgba(255, 74, 74, 0);
            }
        }

        .pulse {
            animation: pulse 2s infinite;
        }

        /* Audio wave animation */
        .audio-wave {
            display: flex;
            align-items: center;
            height: 30px;
        }

        .audio-wave .bar {
            width: 3px;
            margin: 0 1px;
            border-radius: 1px;
            background-color: var(--primary);
            animation: audio-wave 0.8s infinite ease-in-out;
        }

        .audio-wave .bar:nth-child(2n) {
            animation-delay: 0.16s;
        }

        .audio-wave .bar:nth-child(3n) {
            animation-delay: 0.32s;
        }

        @keyframes audio-wave {
            0%, 100% {
                height: 6px;
            }
            50% {
                height: 20px;
            }
        }
    </style>
</head>
<body class="antialiased min-h-screen transition-colors bg-[var(--light-bg)] text-[var(--light-text)] dark:bg-[var(--dark-bg)] dark:text-[var(--dark-text)]">
    <div class="container mx-auto px-4 py-8 max-w-6xl">
        <header class="mb-6">
            <h1 class="text-3xl font-bold text-center text-[var(--primary)]">VFR Radio Communication Practice</h1>
            <p class="text-center mt-2 opacity-75">Practice your pilot radio communications for VFR scenarios</p>
        </header>

        <!-- Microphone Permission Modal -->
        <div id="permission-modal" class="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50 hidden">
            <div class="bg-white dark:bg-gray-800 rounded-lg p-6 max-w-md mx-4">
                <h2 class="text-xl font-bold mb-4">Microphone Access</h2>
                <p class="mb-4">
                    This app offers an audio recording feature that allows you to practice your radio calls by speaking them, just like in a real aircraft.
                </p>
                <p class="mb-4">
                    To use this feature, we need permission to access your microphone. Your recordings remain private and are only used for transcription and evaluation.
                </p>
                <div class="flex gap-3 justify-end">
                    <button id="deny-mic-btn" class="px-4 py-2 border border-gray-300 dark:border-gray-600 rounded-md">
                        Use Text Only
                    </button>
                    <button id="allow-mic-btn" class="px-4 py-2 bg-[var(--primary)] text-white rounded-md">
                        Allow Microphone
                    </button>
                </div>
            </div>
        </div>

        <main class="grid grid-cols-1 lg:grid-cols-12 gap-6">
            <!-- Left Side: Scenario and Response -->
            <div class="lg:col-span-7 order-1 flex flex-col gap-6">
                <!-- Scenario Card -->
                <div class="bg-[var(--light-card)] dark:bg-[var(--dark-card)] rounded-lg shadow-md p-5">
                    <div class="flex justify-between items-center mb-3">
                        <h2 class="text-xl font-semibold">Scenario</h2>
                        <button id="new-scenario-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors text-sm">
                            New Scenario
                        </button>
                    </div>
                    <div id="scenario-loading" class="flex items-center justify-center p-6">
                        <div class="loading-dots mr-3">
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                        </div>
                        <p>Generating new scenario...</p>
                    </div>
                    <div id="scenario-description" class="text-lg p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)] hidden">
                        Loading scenario...
                    </div>
                </div>

                <!-- Response Input -->
                <div class="bg-[var(--light-card)] dark:bg-[var(--dark-card)] rounded-lg shadow-md p-5">
                    <div class="flex justify-between items-center mb-3">
                        <h2 class="text-xl font-semibold">Radio Call</h2>
                        <!-- Input Type Toggle -->
                        <div class="flex rounded-md overflow-hidden border border-[var(--light-border)] dark:border-[var(--dark-border)]">
                            <button id="text-mode-btn" class="py-1 px-3 text-sm bg-[var(--primary)] text-white">Text</button>
                            <button id="audio-mode-btn" class="py-1 px-3 text-sm bg-transparent hover:bg-gray-100 dark:hover:bg-gray-700">Audio</button>
                        </div>
                    </div>

                    <!-- Text Input Mode -->
                    <div id="text-input-container">
                        <textarea id="user-response" placeholder="Type your radio communication here..." class="w-full p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)] min-h-[100px] text-base"></textarea>
                        <div class="flex flex-wrap gap-3 mt-4">
                            <button id="submit-response-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors disabled:bg-gray-400 disabled:cursor-not-allowed">
                                Evaluate Radio Call
                            </button>
                            <button id="clear-response-btn" class="bg-transparent border border-[var(--light-border)] dark:border-[var(--dark-border)] hover:bg-[var(--light-border)] dark:hover:bg-[var(--dark-border)] font-medium py-2 px-4 rounded-md transition-colors">
                                Clear Input
                            </button>
                        </div>
                    </div>

                    <!-- Audio Input Mode -->
                    <div id="audio-input-container" class="hidden">
                        <div class="flex flex-col items-center justify-center p-4 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)] min-h-[100px]">
                            <!-- Microphone permissions needed message -->
                            <div id="mic-unavailable" class="text-center p-4">
                                <svg xmlns="http://www.w3.org/2000/svg" class="h-12 w-12 mx-auto mb-3 text-gray-400" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                    <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M12 11c0 3.517-1.009 6.799-2.753 9.571m-3.44-2.04l.054-.09A13.916 13.916 0 008 11a4 4 0 118 0c0 1.017-.07 2.019-.203 3m-2.118 6.844A21.88 21.88 0 0015.171 17m3.839 1.132c.645-2.266.99-4.659.99-7.132A8 8 0 008 4.07M3 15.364c.64-1.319 1-2.8 1-4.364 0-1.457.39-2.823 1.07-4" />
                                </svg>
                                <p class="mb-3">Microphone access is needed for audio recording.</p>
                                <button id="request-mic-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors">
                                    Enable Microphone
                                </button>
                            </div>

                            <!-- Recording indicator -->
                            <div id="recording-indicator" class="hidden mb-4">
                                <div class="flex items-center justify-center">
                                    <div class="w-4 h-4 rounded-full bg-[var(--recording)] pulse mr-2"></div>
                                    <span class="text-[var(--recording)] font-medium">Recording...</span>
                                </div>
                                <div class="audio-wave mt-3">
                                    <div class="bar" style="height: 6px"></div>
                                    <div class="bar" style="height: 10px"></div>
                                    <div class="bar" style="height: 18px"></div>
                                    <div class="bar" style="height: 14px"></div>
                                    <div class="bar" style="height: 8px"></div>
                                    <div class="bar" style="height: 16px"></div>
                                    <div class="bar" style="height: 12px"></div>
                                    <div class="bar" style="height: 7px"></div>
                                    <div class="bar" style="height: 17px"></div>
                                    <div class="bar" style="height: 11px"></div>
                                </div>
                            </div>

                            <!-- Audio controls -->
                            <div id="audio-controls" class="flex flex-col items-center hidden">
                                <button id="record-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors mb-3 flex items-center">
                                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                                    </svg>
                                    Start Recording
                                </button>
                                
                                <div id="audio-playback" class="hidden w-full">
                                    <audio id="audio-player" controls class="w-full mb-3"></audio>
                                    <div class="flex gap-3 justify-center">
                                        <button id="record-again-btn" class="bg-transparent border border-[var(--light-border)] dark:border-[var(--dark-border)] hover:bg-[var(--light-border)] dark:hover:bg-[var(--dark-border)] font-medium py-2 px-4 rounded-md transition-colors">
                                            Record Again
                                        </button>
                                        <button id="submit-audio-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors">
                                            Evaluate Recording
                                        </button>
                                    </div>
                                </div>
                            </div>

                            <!-- Transcription -->
                            <div id="transcription-container" class="w-full mt-4 hidden">
                                <h3 class="text-sm font-medium opacity-75 mb-2">Transcription</h3>
                                <p id="transcription-text" class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)]">
                                    Transcription will appear here...
                                </p>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Feedback Section -->
                <div class="bg-[var(--light-card)] dark:bg-[var(--dark-card)] rounded-lg shadow-md p-5 hidden" id="feedback-container">
                    <h2 class="text-xl font-semibold mb-3">Feedback</h2>
                    <div id="feedback-loading" class="py-4 flex items-center">
                        <div class="loading-dots mr-3">
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                        </div>
                        <p>Analyzing your radio call...</p>
                    </div>
                    <div id="feedback-content" class="hidden">
                        <div class="mb-4 p-4 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)]">
                            <div class="flex items-center mb-2">
                                <div id="score-indicator" class="w-8 h-8 rounded-full bg-green-500 flex items-center justify-center text-white font-bold mr-2">A</div>
                                <h3 class="text-lg font-semibold">Score: <span id="score-value">95%</span></h3>
                            </div>
                            <div id="feedback-details" class="prose dark:prose-invert max-w-none"></div>
                        </div>
                        <div class="p-4 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)]">
                            <h3 class="text-lg font-semibold mb-2">Example Correct Response</h3>
                            <p id="correct-response" class="font-mono text-sm"></p>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Right Side: Flight Information -->
            <div class="lg:col-span-5 order-2 flex flex-col gap-6">
                <div class="bg-[var(--light-card)] dark:bg-[var(--dark-card)] rounded-lg shadow-md p-5 flex-grow">
                    <h2 class="text-xl font-semibold mb-3">Flight Information</h2>
                    
                    <!-- Airport and Diagram -->
                    <div class="mb-4">
                        <div class="flex gap-3 mb-3">
                            <div class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md flex-1">
                                <p class="text-sm opacity-75">Airport</p>
                                <p id="airport" class="font-medium">KJFK - John F. Kennedy International</p>
                            </div>
                            <div class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md">
                                <p class="text-sm opacity-75">Airport Type</p>
                                <p id="airport-type" class="font-medium">Towered</p>
                            </div>
                        </div>
                        <div class="airport-diagram" id="airport-diagram"></div>
                    </div>
                    
                    <!-- Aircraft Info -->
                    <div class="grid grid-cols-2 gap-3 mb-4">
                        <div class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md">
                            <p class="text-sm opacity-75">Aircraft Type</p>
                            <p id="aircraft-type" class="font-medium">C172</p>
                        </div>
                        <div class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md">
                            <p class="text-sm opacity-75">Tail Number</p>
                            <p id="tail-number" class="font-medium">N12345</p>
                        </div>
                    </div>
                    
                    <!-- Weather Information (shown only when weatherInfo is available) -->
                    <div id="weather-container" class="p-3 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md">
                        <p class="text-sm opacity-75">Weather Information</p>
                        <p id="weather-info" class="font-medium">Loading weather information...</p>
                    </div>
                </div>
            </div>
        </main>
        
        <!-- API Key Settings -->
        <div id="api-key-container" class="mt-6 rounded-lg">
            <!-- Settings form - hidden when API key is present -->
            <div id="api-key-form">
                <h2 class="text-xl font-semibold mb-3">Settings</h2>
                <div class="mb-4">
                    <label for="openai-api-key" class="block text-sm font-medium mb-1">OpenAI API Key <button id="api-key-info-btn" class="text-xs text-blue-500">(Info)</button></label>
                    <div class="flex">
                        <input type="password" id="openai-api-key" placeholder="Enter your OpenAI API key" 
                            class="flex-grow p-2 border border-[var(--light-border)] dark:border-[var(--dark-border)] rounded-md bg-[var(--light-bg)] dark:bg-[var(--dark-bg)]">
                        <button id="save-api-key" class="ml-2 bg-[var(--primary)] hover:bg-[var(--accent)] text-white font-medium py-2 px-4 rounded-md transition-colors">Save</button>
                    </div>
                    <p class="text-xs mt-1 opacity-75">Required for speech-to-text transcription and text generation. Your API key is only stored locally in your browser.</p>
                </div>
            </div>
            <!-- Super minimal API key status - shown when API key is present -->
            <div id="api-key-status" class="hidden text-right">
                <button id="clear-api-key" class="text-xs text-gray-300 hover:text-gray-500 dark:text-gray-600 dark:hover:text-gray-400">clear api key</button>
            </div>
        </div>
    </div>

    <script>
        // Check for dark mode preference
        if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches) {
            document.body.classList.add('dark');
        }

        // Listen for changes in color scheme preference
        window.matchMedia('(prefers-color-scheme: dark)').addEventListener('change', event => {
            if (event.matches) {
                document.body.classList.add('dark');
            } else {
                document.body.classList.remove('dark');
            }
        });

        // DOM Elements
        const scenarioDescription = document.getElementById('scenario-description');
        const scenarioLoading = document.getElementById('scenario-loading');
        const weatherInfo = document.getElementById('weather-info');
        const weatherContainer = document.getElementById('weather-container');
        const newScenarioBtn = document.getElementById('new-scenario-btn');
        
        // Permission elements
        const permissionModal = document.getElementById('permission-modal');
        const allowMicBtn = document.getElementById('allow-mic-btn');
        const denyMicBtn = document.getElementById('deny-mic-btn');
        const requestMicBtn = document.getElementById('request-mic-btn');
        const micUnavailable = document.getElementById('mic-unavailable');
        
        // Input mode elements
        const textModeBtn = document.getElementById('text-mode-btn');
        const audioModeBtn = document.getElementById('audio-mode-btn');
        const textInputContainer = document.getElementById('text-input-container');
        const audioInputContainer = document.getElementById('audio-input-container');
        
        // Text input elements
        const userResponseInput = document.getElementById('user-response');
        const submitResponseBtn = document.getElementById('submit-response-btn');
        const clearResponseBtn = document.getElementById('clear-response-btn');
        
        // Audio input elements
        const recordBtn = document.getElementById('record-btn');
        const recordingIndicator = document.getElementById('recording-indicator');
        const audioControls = document.getElementById('audio-controls');
        const audioPlayback = document.getElementById('audio-playback');
        const audioPlayer = document.getElementById('audio-player');
        const recordAgainBtn = document.getElementById('record-again-btn');
        const submitAudioBtn = document.getElementById('submit-audio-btn');
        const transcriptionContainer = document.getElementById('transcription-container');
        const transcriptionText = document.getElementById('transcription-text');
        
        // Feedback elements
        const feedbackContainer = document.getElementById('feedback-container');
        const feedbackLoading = document.getElementById('feedback-loading');
        const feedbackContent = document.getElementById('feedback-content');
        const scoreIndicator = document.getElementById('score-indicator');
        const scoreValue = document.getElementById('score-value');
        const feedbackDetails = document.getElementById('feedback-details');
        const correctResponse = document.getElementById('correct-response');

        // Flight info elements
        const aircraftTypeEl = document.getElementById('aircraft-type');
        const tailNumberEl = document.getElementById('tail-number');
        const airportTypeEl = document.getElementById('airport-type');
        const airportEl = document.getElementById('airport');
        const airportDiagramEl = document.getElementById('airport-diagram');

        // Current scenario
        let currentScenario = null;
        
        // Audio recording variables
        let mediaRecorder = null;
        let audioChunks = [];
        let audioBlob = null;
        let audioURL = null;
        let isRecording = false;
        let microphoneInitialized = false;

        // Sample scenarios for few-shot learning prompt (simplified structure)
        const fewShotSamples = [
            {
                title: "Pre-departure Taxi at Palo Alto Airport",
                description: "You are parked at the main ramp and need to request taxi clearance from ground control for departure to the east on runway 31.",
                atcCall: null,
                weatherInfo: "Palo Alto Airport, information Alpha. Winds 310 at 8 knots. Visibility 10 miles. Clear below 12,000. Temperature 22, dew point 14. Altimeter 29.92. Landing and departing runway 31. Advise on initial contact you have information Alpha.",
                aircraft: "Cessna 172 Skyhawk",
                tailNumber: "N5678P",
                airport: "KPAO - Palo Alto Airport",
                isTowered: true
            },
            {
                title: "Traffic Advisory Response",
                description: "You are flying 15 miles east at 4,500 feet MSL, heading 270Â°. You have received the following traffic advisory from Approach. Respond appropriately.",
                atcCall: "Cessna Seven One Two Three Four, traffic, two o'clock, five miles, eastbound, altitude indicates three thousand five hundred.",
                weatherInfo: "",
                aircraft: "Cessna 172 Skyhawk",
                tailNumber: "N71234",
                airport: "KOAK - Oakland International Airport",
                isTowered: true
            },
            {
                title: "Position Report at Uncontrolled Airport",
                description: "You are flying the downwind leg in the traffic pattern for runway 27 at traffic pattern altitude. You need to make your position report on CTAF.",
                atcCall: null,
                weatherInfo: "Reid-Hillview Automated Weather Observation, 1845 Zulu. Wind 250 at 6 knots. Visibility 10 miles. Clear below 12,000. Temperature 23 Celsius, dew point 14 Celsius. Altimeter 29.92. Runway 31L in use.",
                aircraft: "Cessna 152",
                tailNumber: "N98765",
                airport: "KRHV - Reid-Hillview Airport", 
                isTowered: false
            },
            {
                title: "Emergency Declaration",
                description: "You are flying 20 miles south at 5,500 feet MSL. Your engine has started running rough and you suspect carburetor icing. You need to declare an emergency to ATC.",
                atcCall: null,
                weatherInfo: "",
                aircraft: "Piper Cherokee",
                tailNumber: "N4567A",
                airport: "KSFO - San Francisco International Airport",
                isTowered: true
            }
        ];
        
        // Generate a simple airport diagram
        function generateAirportDiagram(container, isTowered) {
            // Create a simpler airport diagram with HTML/CSS
            const isDarkMode = document.body.classList.contains('dark');
            const bgColor = isDarkMode ? '#262626' : '#F0F0F0';
            const runwayColor = isDarkMode ? '#505050' : '#333333';
            const taxiwayColor = isDarkMode ? '#364968' : '#6B8CCF';
            const textColor = isDarkMode ? '#E0E0E0' : '#333333';
            
            container.innerHTML = `
                <div style="width:100%; height:100%; background-color:${bgColor}; position:relative; border-radius:0.5rem; overflow:hidden;">
                    <!-- North indicator -->
                    <div style="position:absolute; top:15px; left:15px; color:${textColor}; border:1px solid ${textColor}; width:24px; height:24px; border-radius:50%; text-align:center; line-height:22px;">
                        N
                    </div>
                    
                    <!-- Primary runway -->
                    <div style="position:absolute; top:50%; left:50%; transform:translate(-50%, -50%) rotate(45deg); background-color:${runwayColor}; width:70%; height:20px;"></div>
                    
                    ${isTowered ? 
                    `<!-- Secondary runway (towered) -->
                    <div style="position:absolute; top:50%; left:50%; transform:translate(-50%, -50%) rotate(90deg); background-color:${runwayColor}; width:60%; height:16px;"></div>` : ''}
                    
                    <!-- Terminal area -->
                    <div style="position:absolute; bottom:20px; left:50%; transform:translateX(-50%); background-color:${isDarkMode ? '#888888' : '#BBBBBB'}; width:120px; height:20px;"></div>
                    
                    <!-- Taxiway -->
                    <div style="position:absolute; bottom:50px; left:50%; transform:translateX(-50%); background-color:${taxiwayColor}; width:70%; height:8px;"></div>
                </div>
            `;
            
            return container;
        }
        
        // Update flight information display
        function updateFlightInfoDisplay(scenario) {
            // Basic aircraft and airport information
            aircraftTypeEl.textContent = scenario.aircraft;
            tailNumberEl.textContent = scenario.tailNumber;
            airportEl.textContent = scenario.airport;
            airportTypeEl.textContent = scenario.isTowered ? "Towered" : "Uncontrolled";
            
            // Generate airport diagram
            generateAirportDiagram(airportDiagramEl, scenario.isTowered);
            
            // Weather information - only show if there's weather info available
            if (scenario.weatherInfo && scenario.weatherInfo.trim() !== '') {
                weatherInfo.textContent = scenario.weatherInfo;
                weatherContainer.classList.remove('hidden');
            } else {
                weatherContainer.classList.add('hidden');
            }
        }
        
        // Show permission modal for microphone access
        function showMicrophonePermissionModal() {
            permissionModal.classList.remove('hidden');
        }
        
        // Request microphone permission
        async function requestMicrophonePermission() {
            try {
                // Hide permission modal
                permissionModal.classList.add('hidden');
                
                // Request microphone access
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // If we got here, permission was granted
                initAudioRecording(stream);
                
                // Update UI
                micUnavailable.classList.add('hidden');
                audioControls.classList.remove('hidden');
                
                // Set flag
                microphoneInitialized = true;
                
                // Enable audio mode button
                audioModeBtn.disabled = false;
                
            } catch (err) {
                console.error("Error accessing microphone:", err);
                
                // Update UI to show error
                micUnavailable.classList.remove('hidden');
                audioControls.classList.add('hidden');
                
                // Show error message
                showToast('Could not access microphone. Check your browser permissions.', true);
                
                // Switch back to text mode
                toggleInputMode('text');
            }
        }
        
        // Toggle between text and audio input modes
        function toggleInputMode(mode) {
            if (mode === 'text') {
                textModeBtn.classList.add('bg-[var(--primary)]', 'text-white');
                textModeBtn.classList.remove('bg-transparent', 'hover:bg-gray-100', 'dark:hover:bg-gray-700');
                
                audioModeBtn.classList.remove('bg-[var(--primary)]', 'text-white');
                audioModeBtn.classList.add('bg-transparent', 'hover:bg-gray-100', 'dark:hover:bg-gray-700');
                
                textInputContainer.classList.remove('hidden');
                audioInputContainer.classList.add('hidden');
            } else { // audio mode
                // Check if microphone is initialized
                if (!microphoneInitialized) {
                    // Show the permission modal
                    showMicrophonePermissionModal();
                    return;
                }
                
                audioModeBtn.classList.add('bg-[var(--primary)]', 'text-white');
                audioModeBtn.classList.remove('bg-transparent', 'hover:bg-gray-100', 'dark:hover:bg-gray-700');
                
                textModeBtn.classList.remove('bg-[var(--primary)]', 'text-white');
                textModeBtn.classList.add('bg-transparent', 'hover:bg-gray-100', 'dark:hover:bg-gray-700');
                
                audioInputContainer.classList.remove('hidden');
                textInputContainer.classList.add('hidden');
                
                // Reset audio recording UI
                resetAudioRecording();
            }
        }
        
        // Initialize audio recording with a given stream
        function initAudioRecording(stream) {
            try {
                // Create media recorder with MIME types that OpenAI supports
                // Options in order of preference: mp3, m4a, wav, or webm
                const mimeTypes = [
                    'audio/mp3',
                    'audio/mpeg',
                    'audio/m4a',
                    'audio/wav',
                    'audio/webm'
                ];
                
                // Find the first supported MIME type
                let mimeType = '';
                for (const type of mimeTypes) {
                    if (MediaRecorder.isTypeSupported(type)) {
                        mimeType = type;
                        break;
                    }
                }
                
                // Fallback to default if none are supported
                if (!mimeType) {
                    console.log("None of the preferred MIME types are supported, using default format");
                    mediaRecorder = new MediaRecorder(stream);
                } else {
                    console.log(`Using MIME type: ${mimeType}`);
                    mediaRecorder = new MediaRecorder(stream, { mimeType });
                }
                
                // Set up event handlers
                mediaRecorder.onstart = () => {
                    audioChunks = [];
                    isRecording = true;
                    updateRecordingUI(true);
                };
                
                mediaRecorder.ondataavailable = (event) => {
                    audioChunks.push(event.data);
                };
                
                mediaRecorder.onstop = async () => {
                    isRecording = false;
                    updateRecordingUI(false);
                    
                    // Create audio blob and URL
                    // We don't specify the type here to ensure it matches the recorded format
                    audioBlob = new Blob(audioChunks);
                    audioURL = URL.createObjectURL(audioBlob);
                    
                    // Update audio player
                    audioPlayer.src = audioURL;
                    
                    // Show audio playback UI
                    recordingIndicator.classList.add('hidden');
                    audioPlayback.classList.remove('hidden');
                    
                    // Transcribe the audio using OpenAI's Speech-to-Text API
                    await transcribeAudio(audioBlob);
                };
                
                // Enable record button
                recordBtn.disabled = false;
                
            } catch (err) {
                console.error("Error initializing audio recording:", err);
                showToast('Error initializing audio recording', true);
            }
        }
        
        // Update UI during recording
        function updateRecordingUI(isRecording) {
            if (isRecording) {
                recordBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M21 12a9 9 0 11-18 0 9 9 0 0118 0z" />
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 10a1 1 0 011-1h4a1 1 0 011 1v4a1 1 0 01-1 1h-4a1 1 0 01-1-1v-4z" />
                    </svg>
                    Stop Recording
                `;
                recordBtn.classList.remove('bg-[var(--primary)]', 'hover:bg-[var(--accent)]');
                recordBtn.classList.add('bg-[var(--recording)]', 'hover:bg-red-600');
                recordingIndicator.classList.remove('hidden');
            } else {
                recordBtn.innerHTML = `
                    <svg xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 mr-2" fill="none" viewBox="0 0 24 24" stroke="currentColor">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z" />
                    </svg>
                    Start Recording
                `;
                recordBtn.classList.add('bg-[var(--primary)]', 'hover:bg-[var(--accent)]');
                recordBtn.classList.remove('bg-[var(--recording)]', 'hover:bg-red-600');
            }
        }
        
        // Reset audio recording UI
        function resetAudioRecording() {
            recordingIndicator.classList.add('hidden');
            audioPlayback.classList.add('hidden');
            transcriptionContainer.classList.add('hidden');
            
            if (audioURL) {
                URL.revokeObjectURL(audioURL);
                audioURL = null;
            }
            
            audioBlob = null;
            audioChunks = [];
            
            updateRecordingUI(false);
        }
        
        // Transcribe audio using OpenAI's Speech-to-Text API
        async function transcribeAudio(audioBlob) {
            try {
                transcriptionText.textContent = "Processing audio...";
                
                // Get API key from local storage
                let apiKey = localStorage.getItem('openai_api_key');
                
                if (!apiKey) {
                    transcriptionText.textContent = "OpenAI API key required for transcription.";
                    showToast("OpenAI API key required. Please add your API key in the settings section below.", true);
                    // Scroll to settings section
                    document.getElementById('api-key-container').scrollIntoView({ behavior: 'smooth' });
                    return;
                }
                
                // Determine file extension based on the MIME type
                let fileExtension = 'webm';
                if (audioBlob.type) {
                    const mimeType = audioBlob.type.toLowerCase();
                    if (mimeType.includes('mp3') || mimeType.includes('mpeg')) {
                        fileExtension = 'mp3';
                    } else if (mimeType.includes('wav')) {
                        fileExtension = 'wav';
                    } else if (mimeType.includes('m4a')) {
                        fileExtension = 'm4a';
                    }
                }
                
                // Create unique filename for the audio file
                const fileName = generateFileName('aviation-radio', fileExtension);
                
                // Create FormData for OpenAI API
                const formData = new FormData();
                formData.append('file', audioBlob, fileName);
                formData.append('model', 'whisper-1');
                formData.append('language', 'en');
                formData.append('prompt', 'This is a pilot radio communication in standard aviation phraseology');
                
                // Show loading state
                transcriptionContainer.classList.remove('hidden');
                transcriptionText.innerHTML = `
                    <div class="flex items-center">
                        <div class="loading-dots mr-3">
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                            <span class="bg-[var(--primary)]"></span>
                        </div>
                        <p>Transcribing with OpenAI...</p>
                    </div>
                `;
                
                // Call OpenAI API
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                    method: 'POST',
                    headers: {
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: formData
                });
                
                // Handle API response
                if (response.ok) {
                    const data = await response.json();
                    transcriptionText.textContent = data.text;
                    
                    // Format the transcription text specifically for aviation
                    let formattedText = data.text;
                    
                    // Replace common number patterns with aviation format
                    // Replace frequencies (e.g. 119.5 -> one one niner point five)
                    formattedText = formattedText.replace(/(\d+)\.(\d+)/g, (match, p1, p2) => {
                        // Convert each digit to spoken word with "niner" for 9, etc.
                        const p1Spoken = p1.split('').map(digitsToWords).join(' ');
                        const p2Spoken = p2.split('').map(digitsToWords).join(' ');
                        return `${p1Spoken} point ${p2Spoken}`;
                    });
                    
                    // Show both original and formatted
                    transcriptionText.innerHTML = `
                        <div class="mb-2">
                            <p class="text-sm font-medium opacity-75">Original Transcription:</p>
                            <p>${data.text}</p>
                        </div>
                        <div>
                            <p class="text-sm font-medium opacity-75">Formatted for Radio:</p>
                            <p>${formattedText}</p>
                        </div>
                        <div class="mt-4">
                            <button id="use-transcription-btn" class="bg-[var(--primary)] hover:bg-[var(--accent)] text-white text-sm font-medium py-1 px-3 rounded-md transition-colors">
                                Use for Evaluation
                            </button>
                        </div>
                    `;
                    
                    // Add event listener to use transcription button
                    document.getElementById('use-transcription-btn').addEventListener('click', () => {
                        evaluateResponse(formattedText, true);
                    });
                    
                } else {
                    const errorData = await response.json().catch(() => ({ error: { message: 'Unknown error occurred' } }));
                    console.error("OpenAI API error:", errorData);
                    
                    // Handle API key errors
                    if (response.status === 401) {
                        localStorage.removeItem('openai_api_key');
                        transcriptionText.textContent = "Invalid OpenAI API key. Please try again with a valid key.";
                    } else {
                        transcriptionText.textContent = `Error transcribing audio: ${errorData.error?.message || 'Unknown error'}`;
                    }
                }
            } catch (err) {
                console.error("Error transcribing audio:", err);
                transcriptionText.textContent = "Error transcribing audio. Please try again.";
            }
        }
        
        // Helper function to convert digits to spoken aviation words
        function digitsToWords(digit) {
            const digitMap = {
                '0': 'zero',
                '1': 'one',
                '2': 'two',
                '3': 'tree',
                '4': 'four',
                '5': 'fife',
                '6': 'six',
                '7': 'seven',
                '8': 'eight',
                '9': 'niner'
            };
            return digitMap[digit] || digit;
        }
        
        // Helper function to generate a unique file name with timestamp
        function generateFileName(prefix, extension) {
            const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
            return `${prefix}-${timestamp}.${extension}`;
        }
        
        // Show a small info panel about the OpenAI API key
        function showApiKeyInfo() {
            const infoHtml = `
                <div class="fixed inset-0 bg-black bg-opacity-50 flex items-center justify-center z-50" id="api-key-info-modal">
                    <div class="bg-white dark:bg-gray-800 rounded-lg p-6 max-w-md mx-4">
                        <h2 class="text-xl font-bold mb-4">About OpenAI API Key</h2>
                        <p class="mb-4">
                            This application uses OpenAI's APIs for both speech-to-text (Whisper) and text generation (GPT-4o).
                        </p>
                        <p class="mb-4">
                            To use these features, you need to provide your own OpenAI API key. The key is stored only in your browser's local storage and is never sent to our servers.
                        </p>
                        <p class="mb-4">
                            You can get an API key by signing up at <a href="https://platform.openai.com/signup" target="_blank" class="text-blue-500 underline">platform.openai.com</a>.
                        </p>
                        <div class="flex justify-end">
                            <button id="close-api-info-btn" class="px-4 py-2 bg-[var(--primary)] text-white rounded-md">
                                Got it
                            </button>
                        </div>
                    </div>
                </div>
            `;
            
            document.body.insertAdjacentHTML('beforeend', infoHtml);
            
            document.getElementById('close-api-info-btn').addEventListener('click', () => {
                document.getElementById('api-key-info-modal').remove();
            });
        }
        
        // Generate a new scenario using OpenAI's GPT-4o model
        async function generateScenario() {
            // Show loading indicator
            scenarioLoading.classList.remove('hidden');
            scenarioDescription.classList.add('hidden');
            newScenarioBtn.disabled = true;
            submitResponseBtn.disabled = true;
            
            // Sample scenario objects to use as examples
            const examples = JSON.stringify(fewShotSamples, null, 2);
            
            try {
                // Get API key
                const apiKey = localStorage.getItem('openai_api_key');
                if (!apiKey) {
                    showToast("OpenAI API key required. Please add your API key in the settings section below.", true);
                    // Scroll to settings section
                    document.getElementById('api-key-container').scrollIntoView({ behavior: 'smooth' });
                    // Fall back to a random sample scenario
                    currentScenario = fewShotSamples[Math.floor(Math.random() * fewShotSamples.length)];
                    displayScenario(currentScenario);
                    return;
                }
                
                // Create prompt with instructions for scenario generation
                const prompt = `Generate one new detailed VFR aviation radio communication scenario object for a pilot training application. The scenario should be diverse, realistic, and educational. Each scenario should include enough details for a pilot to craft an appropriate radio call.

Here are some examples of the format and variety of scenarios:

${examples}

Focus on creating scenarios that cover a wide range of common VFR communications, including:
- Initial contact with different ATC facilities (Ground, Tower, Approach, Center)
- Position reporting at towered and uncontrolled airports
- Taxi, takeoff, and landing requests
- Frequency changes
- Flight following requests
- Navigating through different airspaces
- Traffic advisories
- Weather information requests
- Emergency or abnormal situations (occasionally)

Your generated scenario should match this exact JSON structure with all fields. Make sure to:
1. Provide a clear, descriptive title
2. Keep the description concise and focused on the situation and task
3. Don't repeat information in the description that's already present in other fields
   - Don't mention ATIS code or airport details in the description if they're already in the weatherInfo or airport fields
   - The user will see the weatherInfo and airport fields separately alongside the description
4. Only include atcCall if there is actual ATC dialog
5. Only include weatherInfo when relevant and otherwise leave it as an empty string
6. Choose appropriate aircraft types and real airports across the United States
7. Use proper aviation terminology and phraseology

Generate only ONE scenario object that strictly follows the given structure. Return ONLY valid JSON with no additional explanations or markdown formatting. The entire response should be parseable with JSON.parse().`;

                // Call OpenAI API
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [
                            {
                                role: 'system',
                                content: 'You are a specialized aviation training assistant that creates realistic VFR radio communication scenarios in JSON format.'
                            },
                            {
                                role: 'user',
                                content: prompt
                            }
                        ],
                        temperature: 0.7
                    })
                });
                
                // Handle API response
                if (response.ok) {
                    const data = await response.json();
                    const responseContent = data.choices[0].message.content.trim();
                    
                    try {
                        // Parse the JSON response
                        const generatedScenario = JSON.parse(responseContent);
                        
                        // Use the generated scenario
                        currentScenario = generatedScenario;
                        
                        // Update UI
                        displayScenario(currentScenario);
                    } catch (e) {
                        console.error("Failed to parse scenario JSON:", e);
                        // Fall back to a random sample scenario
                        currentScenario = fewShotSamples[Math.floor(Math.random() * fewShotSamples.length)];
                        displayScenario(currentScenario);
                        showToast("Error parsing generated scenario. Using sample scenario instead.", true);
                    }
                } else {
                    // Handle error response
                    const errorData = await response.json().catch(() => ({ error: { message: 'Unknown error occurred' } }));
                    console.error("OpenAI API error:", errorData);
                    
                    // Handle API key errors
                    if (response.status === 401) {
                        localStorage.removeItem('openai_api_key');
                        showToast("Invalid OpenAI API key. Please check your settings.", true);
                    } else {
                        showToast(`Error generating scenario: ${errorData.error?.message || 'Unknown error'}`, true);
                    }
                    
                    // Fall back to a random sample scenario
                    currentScenario = fewShotSamples[Math.floor(Math.random() * fewShotSamples.length)];
                    displayScenario(currentScenario);
                }
            } catch (err) {
                console.error("Error generating scenario:", err);
                // Fall back to a random sample scenario
                currentScenario = fewShotSamples[Math.floor(Math.random() * fewShotSamples.length)];
                displayScenario(currentScenario);
                showToast(`Error: ${err.message}`, true);
            }
        }
        
        // Display the scenario in the UI
        function displayScenario(scenario) {
            // Hide loading indicator
            scenarioLoading.classList.add('hidden');
            scenarioDescription.classList.remove('hidden');
            newScenarioBtn.disabled = false;
            submitResponseBtn.disabled = false;
            
            // Create the scenario text
            let scenarioText = `<p>${scenario.description}</p>`;
            
            // Add ATC communication if present
            if (scenario.atcCall) {
                scenarioText += `<p class="mt-3 bg-[var(--light-border)] dark:bg-[var(--dark-border)] p-2 rounded-md font-medium">"${scenario.atcCall}"</p>`;
            }
            
            // Display the scenario
            scenarioDescription.innerHTML = scenarioText;
            
            // Update the flight information display
            updateFlightInfoDisplay(scenario);
            
            // Reset input
            userResponseInput.value = '';
            resetAudioRecording();
            feedbackContainer.classList.add('hidden');
        }

        // Show toast notification
        function showToast(message, isError = false) {
            const toast = document.createElement('div');
            toast.className = `fixed top-4 right-4 ${isError ? 'bg-red-500' : 'bg-green-600'} text-white p-3 rounded-md shadow-lg z-50`;
            toast.textContent = message;
            document.body.appendChild(toast);
            setTimeout(() => {
                toast.remove();
            }, 3000);
        }
        
        // Evaluate user response using OpenAI's GPT-4o model
        async function evaluateResponse(responseText, isAudio = false) {
            if (!responseText || responseText.trim() === '') {
                showToast('Please provide a radio communication before submitting', true);
                return;
            }
            
            // Show feedback section with loading state
            feedbackContainer.classList.remove('hidden');
            feedbackLoading.classList.remove('hidden');
            feedbackContent.classList.add('hidden');
            submitResponseBtn.disabled = true;
            if (isAudio) submitAudioBtn.disabled = true;
            
            try {
                // Get API key
                const apiKey = localStorage.getItem('openai_api_key');
                if (!apiKey) {
                    showToast("OpenAI API key required. Please add your API key in the settings section below.", true);
                    // Scroll to settings section
                    document.getElementById('api-key-container').scrollIntoView({ behavior: 'smooth' });
                    // Hide feedback section
                    feedbackContainer.classList.add('hidden');
                    submitResponseBtn.disabled = false;
                    if (isAudio) submitAudioBtn.disabled = false;
                    return;
                }
                
                // Build weather information for prompt
                const weatherBlock = currentScenario.weatherInfo && currentScenario.weatherInfo.trim() !== '' ? 
                    `\nWeather Information:\n${currentScenario.weatherInfo}` : '';
                
                // Add source information
                const sourceInfo = isAudio ? 
                    `\nNote: This response was provided via audio recording and then transcribed.` : 
                    `\nNote: This response was typed directly by the user.`;
                
                // Create prompt with proper context for OpenAI to evaluate, with improved instructions for numeric phraseology
                const prompt = `You are an FAA examiner evaluating a pilot's radio communication for a VFR scenario. Rate the following radio call and provide feedback based on standard aviation communication practices:

Scenario: ${currentScenario.title}
${currentScenario.description}
${currentScenario.atcCall ? 'ATC said: "' + currentScenario.atcCall + '"' : ''}${weatherBlock}

Flight Info:
- Aircraft: ${currentScenario.aircraft}
- Tail Number: ${currentScenario.tailNumber}
- Airport: ${currentScenario.airport}${sourceInfo}

Pilot's actual radio call:
"${responseText}"

IMPORTANT EVALUATION GUIDELINES:
1. Allow for situation-appropriate abbreviations and variations as used in real-world radio communications:
   - Aircraft type instead of full tail number when appropriate (e.g., "Cessna six niner zero" instead of "November one four six niner zero")
   - Airport name instead of identifier when commonly used (e.g., "Half Moon traffic" vs "KHAF traffic")

2. Strongly favor spelled-out aviation numeric phraseology over digits:
   - Give higher scores when pilots use "one one niner point five" rather than "119.5"
   - Reward proper aviation number pronunciation (e.g., "niner" for 9, "tree" for 3, "fife" for 5)
   - Prefer "three thousand five hundred" over "3,500"
   - Expect headings to be spoken as individual digits (e.g., "heading zero niner zero" not "heading ninety")
   - Expect altitudes as thousands and hundreds (e.g., "six thousand five hundred" not "six five zero zero")
   - Expect frequencies to be spoken with "point" or "decimal" (e.g., "one one niner point eight")

3. Focus only on content that matters in verbal communications:
   - IGNORE capitalization, punctuation, and spelling in the evaluation
   - Focus on whether the essential information is communicated
   - Consider whether the communication would be clear to ATC or other pilots

4. Be lenient on word order when all required information is present and the meaning is clear.

Please evaluate the pilot's radio communication and provide:
1. A letter grade (A, B, C, D, F) and percentage score (0-100%)
2. Specific feedback on what was correct and what needs improvement
3. An example of the proper communication for this specific scenario with the actual details

Format your response as valid JSON that can be parsed by JavaScript's JSON.parse():
{
  "grade": "A-F",
  "score": 85,
  "feedback": "Detailed feedback text here",
  "correctExample": "Exact example of correct communication"
}

Provide ONLY raw JSON in your response with no explanations, additional text, or code block formatting (no \`\`\`).`;

                // Call OpenAI API
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${apiKey}`
                    },
                    body: JSON.stringify({
                        model: 'gpt-4o',
                        messages: [
                            {
                                role: 'system',
                                content: 'You are an FAA examiner evaluating a pilot\'s radio communication for a VFR scenario.'
                            },
                            {
                                role: 'user',
                                content: prompt
                            }
                        ],
                        temperature: 0.7
                    })
                });
                
                // Handle API response
                if (response.ok) {
                    const data = await response.json();
                    const responseContent = data.choices[0].message.content.trim();
                    
                    try {
                        // Parse the JSON response
                        const feedbackData = JSON.parse(responseContent);
                        displayFeedback(feedbackData);
                    } catch (e) {
                        console.error("Failed to parse JSON response:", e);
                        displayErrorFeedback("Failed to parse evaluation response. The API returned an invalid format.");
                    }
                } else {
                    // Handle error response
                    const errorData = await response.json().catch(() => ({ error: { message: 'Unknown error occurred' } }));
                    console.error("OpenAI API error:", errorData);
                    
                    // Handle API key errors
                    if (response.status === 401) {
                        localStorage.removeItem('openai_api_key');
                        displayErrorFeedback("Invalid API key. Please check your OpenAI API key in the settings.");
                    } else {
                        displayErrorFeedback(`Error from OpenAI API: ${errorData.error?.message || 'Unknown error'}`);
                    }
                }
            } catch (err) {
                console.error("Error evaluating response:", err);
                displayErrorFeedback(err.message);
            }
        }

        // Display feedback from evaluation
        function displayFeedback(feedbackData) {
            // Hide loading, show content
            feedbackLoading.classList.add('hidden');
            feedbackContent.classList.remove('hidden');
            
            // Update score indicators
            scoreIndicator.textContent = feedbackData.grade;
            scoreValue.textContent = `${feedbackData.score}%`;
            
            // Set color based on grade
            const scoreColors = {
                'A': 'bg-green-500',
                'B': 'bg-blue-500',
                'C': 'bg-yellow-500',
                'D': 'bg-orange-500',
                'F': 'bg-red-500'
            };
            
            // Reset all color classes first
            Object.values(scoreColors).forEach(color => {
                scoreIndicator.classList.remove(color);
            });
            
            // Add the appropriate color class
            const grade = feedbackData.grade.charAt(0);
            scoreIndicator.classList.add(scoreColors[grade] || 'bg-gray-500');
            
            // Update feedback details
            feedbackDetails.innerHTML = marked.parse(feedbackData.feedback);
            
            // Update correct response example
            correctResponse.textContent = feedbackData.correctExample;
            
            // Re-enable buttons
            submitResponseBtn.disabled = false;
            submitAudioBtn.disabled = false;
        }

        // Display error feedback
        function displayErrorFeedback(errorMessage = null) {
            // Hide loading, show content
            feedbackLoading.classList.add('hidden');
            feedbackContent.classList.remove('hidden');
            
            // Set error display
            scoreIndicator.textContent = '?';
            scoreIndicator.classList.remove(
                'bg-green-500', 'bg-blue-500', 'bg-yellow-500', 'bg-orange-500', 'bg-red-500'
            );
            scoreIndicator.classList.add('bg-gray-500');
            scoreValue.textContent = 'N/A';
            
            // Set error message
            const errorText = errorMessage || 
                "There was an error evaluating your response. Please check your API key or try again later.";
            
            feedbackDetails.innerHTML = `
                <div class="text-red-500 dark:text-red-400">
                    <p>${errorText}</p>
                    <p class="mt-2">If this error persists, please try the following:</p>
                    <ul class="list-disc pl-5 mt-1">
                        <li>Check your OpenAI API key in the settings</li>
                        <li>Ensure your OpenAI account has available credits</li>
                        <li>Try a different browser or clear your cache</li>
                    </ul>
                </div>
            `;
            
            correctResponse.textContent = "N/A";
            
            // Re-enable buttons
            submitResponseBtn.disabled = false;
            submitAudioBtn.disabled = false;
        }

        // Event Listeners
        document.addEventListener('DOMContentLoaded', () => {
            // Initialize API key field with saved value
            const apiKeyInput = document.getElementById('openai-api-key');
            const apiKeyForm = document.getElementById('api-key-form');
            const apiKeyStatus = document.getElementById('api-key-status');
            const clearApiKeyBtn = document.getElementById('clear-api-key');
            const savedApiKey = localStorage.getItem('openai_api_key');
            
            // Function to update UI based on API key presence
            function updateApiKeyUI() {
                const hasApiKey = localStorage.getItem('openai_api_key') !== null;
                const apiKeyContainer = document.getElementById('api-key-container');
                
                if (hasApiKey) {
                    // Hide the form, show the minimal clear button
                    apiKeyForm.classList.add('hidden');
                    apiKeyStatus.classList.remove('hidden');
                    
                    // Make the container extremely minimal
                    apiKeyContainer.classList.remove('bg-[var(--light-card)]', 'dark:bg-[var(--dark-card)]', 'shadow-md', 'p-5');
                    apiKeyContainer.classList.add('p-2', 'mt-4');
                } else {
                    // Show the form, hide the status
                    apiKeyForm.classList.remove('hidden');
                    apiKeyStatus.classList.add('hidden');
                    
                    // Restore the container styling
                    apiKeyContainer.classList.add('bg-[var(--light-card)]', 'dark:bg-[var(--dark-card)]', 'shadow-md', 'p-5');
                    apiKeyContainer.classList.remove('p-2', 'mt-4');
                }
            }
            
            // Initial UI update
            updateApiKeyUI();
            
            if (savedApiKey) {
                apiKeyInput.value = savedApiKey;
            }
            
            // Add save button event listener
            document.getElementById('save-api-key').addEventListener('click', () => {
                const apiKey = apiKeyInput.value.trim();
                if (apiKey) {
                    localStorage.setItem('openai_api_key', apiKey);
                    showToast('API key saved successfully');
                    updateApiKeyUI();
                } else {
                    localStorage.removeItem('openai_api_key');
                    showToast('API key removed');
                    updateApiKeyUI();
                }
            });
            
            // Add clear API key button event listener
            clearApiKeyBtn.addEventListener('click', () => {
                localStorage.removeItem('openai_api_key');
                apiKeyInput.value = '';
                showToast('API key removed');
                updateApiKeyUI();
            });
            
            // Add info button event listener
            document.getElementById('api-key-info-btn').addEventListener('click', showApiKeyInfo);
            
            // Generate initial scenario
            generateScenario();
        });
        
        // Permission modal handlers
        allowMicBtn.addEventListener('click', requestMicrophonePermission);
        
        denyMicBtn.addEventListener('click', () => {
            permissionModal.classList.add('hidden');
            toggleInputMode('text');
        });
        
        requestMicBtn.addEventListener('click', () => {
            showMicrophonePermissionModal();
        });
        
        // Input mode toggle
        textModeBtn.addEventListener('click', () => toggleInputMode('text'));
        audioModeBtn.addEventListener('click', () => toggleInputMode('audio'));
        
        // New scenario button
        newScenarioBtn.addEventListener('click', () => {
            generateScenario();
            // Reset both input modes
            userResponseInput.value = '';
            resetAudioRecording();
            feedbackContainer.classList.add('hidden');
        });
        
        // Text input controls
        submitResponseBtn.addEventListener('click', () => {
            evaluateResponse(userResponseInput.value);
        });
        
        clearResponseBtn.addEventListener('click', () => {
            userResponseInput.value = '';
        });
        
        // Audio recording controls
        recordBtn.addEventListener('click', () => {
            if (!mediaRecorder) {
                showToast('Microphone not initialized. Please enable microphone access.', true);
                return;
            }
            
            if (isRecording) {
                mediaRecorder.stop();
            } else {
                // Reset UI first
                resetAudioRecording();
                
                // Start recording
                try {
                    mediaRecorder.start();
                } catch (err) {
                    console.error("Error starting recording:", err);
                    showToast('Error starting recording. Please try again.', true);
                }
            }
        });
        
        recordAgainBtn.addEventListener('click', () => {
            resetAudioRecording();
        });
        
        submitAudioBtn.addEventListener('click', () => {
            const transcriptionContent = transcriptionText.textContent.trim();
            if (transcriptionContent && transcriptionContent !== 'Transcription will appear here...') {
                // Get the formatted text if available, otherwise use the original text
                const formattedDiv = transcriptionText.querySelector('div:nth-child(2) > p:nth-child(2)');
                const originalDiv = transcriptionText.querySelector('div:nth-child(1) > p:nth-child(2)');
                
                const textToSubmit = formattedDiv ? formattedDiv.textContent : 
                                    (originalDiv ? originalDiv.textContent : transcriptionContent);
                
                evaluateResponse(textToSubmit, true);
            } else {
                showToast('Please wait for transcription to complete before submitting', true);
            }
        });
    </script>
</body>
</html>
